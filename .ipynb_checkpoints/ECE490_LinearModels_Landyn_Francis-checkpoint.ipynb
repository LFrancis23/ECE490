{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d689f1c8-dc50-4491-ab60-a9e4a5442a0d",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# we will need matplotlib for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd93ecb-8121-44f4-8344-91fff8d95d75",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear algebra: Review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f49da13",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Equation of a 2D line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4ee8cb",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "There are two equations of lines\n",
    "\n",
    "1. $y = m x + c$\n",
    "2. $a x + b y + c = 0$\n",
    "\n",
    "What are the advantages or disadvantages of both of those?\n",
    "\n",
    "1. This form includes the slope, and the y intercept.\n",
    "    Cannot represent x = 0\n",
    "    Only 2 parameters\n",
    "2. It can be factored out for intercepts. \n",
    "    3 Parameters\n",
    "\n",
    "\n",
    "A 2D line is the set of all points (x, y) that satisfy the an equation $a x + b y + c = 0$ for given $a, b, c$. For the same line there can be multiple valid parameters $a, b , c$. Either $a$ or $b$ can be zero. But both $a$ and $b$ cannot be zero at the same time. \n",
    "\n",
    "Ideally the equation of line must  be written in the set notation:\n",
    "\n",
    "$\\newcommand{\\bbR}{\\mathbb{R}}$\n",
    "$\\newcommand{\\calL}{\\mathcal{L}}$\n",
    "$\\newcommand{\\calC}{\\mathcal{C}}$\n",
    "$$\\calL(a, b, c) = \\{(x, y): ax + by + c = 0, x \\in \\bbR, y \\in \\bbR \\}$$\n",
    "\n",
    "This equation is read as: the line $\\mathcal{L}$ defined by the paramters $a,b,c$ is the set of all points $(x, y)$ such that it the $x,y$ satisfy the equation $ax + by + c = 0$ and $x$ and $y$ are in the set of all real numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d0a829",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Implicit form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e335584",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Line is a type of curve. Other curves can be parabola, circle etc. Every curve can be represented in implicit form like we did for the line above. In implicit form, the points are *constrained* by one or more equations to lie on the curve. The equations define a test whether the point lies on the curve or not.\n",
    "\n",
    "$$\\calC(p_1, p_2, \\dots, p_n) = \\{(x, y): f(x, y; p_1, p_2, \\dots, p_n) = 0, x \\in \\bbR, y \\in \\bbR\\}$$\n",
    "\n",
    "This equation is read as the curve $\\calC$ defined by the paramters $p_1, p_2, \\dots, p_n$ is the set of all points $(x, y)$ such that it the $x,y$ satisfy the equation $f(x, y; p_1, p_2, \\dots, p_n) = 0$ and $x$ and $y$ are in the set of all real numbers.\n",
    "\n",
    "Take circle with center $(x_0, y_0)$ and radius $r$, as an example. The implicit form is:\n",
    "\n",
    "$$\\calC(x_0, y_0, r) = \\{(x, y): (x-x_0)^2 + (y-y_0)^2 - r^2 = 0, x \\in \\bbR, y \\in \\bbR\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e00327",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Paramteric form of 2D Line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8a5567-1a2a-4fab-935b-6747260fca54",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "A parameteric form defines how the points on the curve are generated from a free paramters. For a line:\n",
    "\n",
    "$$\\calL(d_x, d_y, x_0, y_0) = \\{(d_xr+x_0, d_yr+y_0): r \\in \\bbR \\}$$\n",
    "\n",
    "This equation is read as: the line $\\calL$ defined by the paramters $d_x,d_y,x_0,y_0$ is the set of all points $(d_xr+x_0, d_yr+y_0)$ such that $r$ is any real number.\n",
    "\n",
    "Take circle with center $(x_0, y_0)$ and radius $r$, as an example. The parameteric form is:\n",
    "\n",
    "$$\\calC(x_0, y_0, r) = \\{(r\\cos(\\theta) + x_0, r\\sin(\\theta) + y_0): \\theta \\in [0, 2\\pi)\\}$$\n",
    "\n",
    "In general, the paramteric form of a curve depend on some free paramters and the points are defined as functions of the free parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6aeabd0",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def stylizeax(ax, limits):\n",
    "    \"\"\"Set ax style\"\"\"\n",
    "    minx, maxx, miny, maxy = limits\n",
    "     # x-axis, y=0\n",
    "    ax.annotate(\"\", \n",
    "                xy=(minx, 0),\n",
    "                xytext=(maxx, 0),\n",
    "                arrowprops=dict(arrowstyle=\"<->\"),\n",
    "                color='k')\n",
    "    ax.text(maxx, 0, \"x\")\n",
    "     # y-axis, x=0\n",
    "    ax.annotate(\"\", \n",
    "                xy=(0, miny),\n",
    "                xytext=(0, maxy),\n",
    "                arrowprops=dict(arrowstyle=\"<->\"),\n",
    "                color='k')\n",
    "    ax.text(0, maxy, \"y\")\n",
    "    \n",
    "\n",
    "    ax.grid(True, which='both') # show the grid\n",
    "    ax.set_aspect('equal') # set aspect ratio of the grid to 1:1\n",
    "    \n",
    "    \n",
    "def points_on_line(a, b, c, Npts=6, scale=10):\n",
    "    \"\"\"Generate points on the line ax + by + c = 0\"\"\"\n",
    "    # ax + by + c = 0\n",
    "    # In parameteric form with free parameter r\n",
    "    #   (x, y) = (-b*r + x0, a*r + y0)\n",
    "    # where \n",
    "    #   x0 = - a*c / (a*a + b*b)\n",
    "    #   y0 = - b*c / (a*a + b*b)\n",
    "    # (x0, y0) is the point on the line closest to the origin\n",
    "    uniformgrid = [i/Npts for i in range(-scale*Npts//2, scale*Npts//2, scale)]\n",
    "    x0 = -a*c/(a*a + b*b)\n",
    "    y0 = -b*c/(a*a + b*b)\n",
    "    x = [-b*r + x0 for r in uniformgrid]\n",
    "    y = [ a*r + y0 for r in uniformgrid]\n",
    "    return x, y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106eb5fa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cf6bb7f-4da0-4576-97ed-0a833ff8e4f9",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '-4.9x+4.7y+1.8 = 0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a line ax + by + c = 0\n",
    "# a, b, c = 2.5, -1, -5 # pick numbers by hand\n",
    "\n",
    "# pick a, b, c at random\n",
    "import random\n",
    "scale = 10\n",
    "a, b, c = [scale*(random.random()-0.5) for _ in range(3)] # random number from -10 to 10\n",
    "\n",
    "# Generate some sample points on a line\n",
    "# Parametric form is better here. Can vary lambda and generate points\n",
    "x, y = points_on_line(a, b, c, scale=scale)\n",
    "\n",
    "# Plot the points\n",
    "fig, ax = plt.subplots()\n",
    "#Fig is the entire frame\n",
    "#There can be multiple axes(ax) in a figure\n",
    "stylizeax(ax, (min(x), max(x), min(y), max(y)))\n",
    "ax.plot(x, y, '*-') # the line\n",
    "ax.set_title(f'{a:.1f}x{b:+.1f}y{c:+.1f} = 0') # print the equation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f11e2e1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88918d7-0d7a-4e93-b40d-ad9a0e963afb",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "$\\newcommand{\\bfz}{\\mathbf{z}}\n",
    "\\newcommand{\\bfy}{\\mathbf{y}}\n",
    "\\newcommand{\\bfx}{\\mathbf{x}}\n",
    "\\newcommand{\\bfw}{\\mathbf{w}}\n",
    "\\newcommand{\\bfv}{\\mathbf{v}}\n",
    "\\newcommand{\\bfu}{\\mathbf{u}}$\n",
    " We will denote vectors with bold font notations instead of the usualy $\\vec{x}$ notation. The arrow notation vectors are sometimes called geometric vectors. We will make no such distinction. The set of all real numbers will be denoted as $\\bbR$. The set of all real 2D vectors is written as $\\bbR^2$. When we write $\\bfx \\in \\bbR^2$, it means that $\\bfx$ is in the set of real 2D vectors, hence a 2D real vector. We will write $\\|\\bfx\\|$ for the magnitude of the vector, and $\\bfx \\cdot \\bfy$ for dot product between two vector $\\bfx$ and $\\bfy$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611384df",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## n-D vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e790fc5e-8b33-4a49-9c7a-fc869a7a638a",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "A n-D vector is also written as $\\bfx \\in \\bbR^n$ and the vector has $\\bfx = [x_1; \\dots; x_n]$ $n$ real components. Every vector has a magnitude $\\|\\bfx\\|$ and a direction $\\hat{\\bfx}$. The magnitude and direction are given by:\n",
    "\n",
    "$$ \\|\\bfx\\| = \\sqrt{x_1^2 + x_2^2 + \\dots + x_n^n} \\in \\bbR$$ \n",
    "$$ \\hat{\\bfx} = \\frac{1}{\\|\\bfx\\|} \\bfx \\in \\bbR^n$$\n",
    "\n",
    "The direction vector $\\hat{\\bfx}$ is a unit vector because its magnitide is one i.e. $\\|\\hat{\\bfx}\\| = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2627ae-960a-4c66-8382-0e1f2e3d0ea9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Vector addition\n",
    "\n",
    "Vector addition is element-wise addition\n",
    "\n",
    "$$ \\bfv + \\bfw \n",
    "= \\begin{bmatrix} v_1 \\\\ \\vdots \\\\ v_n \\end{bmatrix} + \\begin{bmatrix} w_1 \\\\ \\vdots \\\\ w_n \\end{bmatrix}\n",
    "= \\begin{bmatrix} v_1 + w_1 \\\\ \\vdots \\\\ v_n + w_n \\end{bmatrix} $$\n",
    "\n",
    "Geometrically the resulting vector can be obtained by triangle law or the parallelogram law.\n",
    "\n",
    "![](https://openstax.org/apps/archive/20221219.191545/resources/8c95eeee388ee88ecb81b6026404d02273fbcb84)\n",
    "\n",
    "Reference: \\[[1](https://openstax.org/books/calculus-volume-3/pages/2-1-vectors-in-the-plane)\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fb6d8c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dot product of vectors\n",
    "\n",
    "Dot product of two vectors is a scalar given by sum of element-wise product.\n",
    "\n",
    "$$ \\bfv \\cdot \\bfu \n",
    "= \\begin{bmatrix} v_1 \\\\ \\vdots \\\\ v_n \\end{bmatrix} \\cdot \\begin{bmatrix} u_1 \\\\ \\vdots \\\\ u_n \\end{bmatrix}\n",
    "= v_1 u_1 + v_2 u_2 + \\cdots + v_n u_n $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7c7e4e-340a-40af-a9f1-08655199b233",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Geometrically, dot product is closely related to the projection. Projection of vector $\\bfv$ on $\\bfu$ is the dot product of $\\bfv$ with the direction of $\\bfu$ \n",
    "\n",
    "$$\\text{proj}_{\\bfu}\\bfv = \\bfv \\cdot \\hat{\\bfu}$$\n",
    "\n",
    "![](https://openstax.org/apps/archive/20221219.191545/resources/263b8d95f699470f4cf6d49170b85118906c5ede)\n",
    "\n",
    "Dot product of vector with itself gives the square of the magnitude $\\bfv \\cdot \\bfv = \\|\\bfv\\|^2$.\n",
    "\n",
    "Reference: \\[[2](https://openstax.org/books/calculus-volume-3/pages/2-3-the-dot-product)\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42ec792",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Matrices "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a5e6e9",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "$\\newcommand{\\bfX}{\\mathbf{X}}$\n",
    "$\\newcommand{\\bfV}{\\mathbf{V}}$\n",
    "$\\newcommand{\\bfU}{\\mathbf{U}}$\n",
    "Matrices are a group of vectors. A matrix can be obtained by vertical stacking of row (horizontal) vectors or horizontal stacking of column (vertical) vectors. It is common to represent all vectors as column vectors unless specified otherwise, so we consider a matrix $\\bfV$ as a horizontal concatenation of column vectors $\\bfv_1, \\bfv_2, \\dots, \\bfv_n$. Let each vector be m-dimensional $\\bfv_i \\in \\bbR^m$.\n",
    "\n",
    "$$\\bfV = \\begin{bmatrix}\\bfv_1 & \\bfv_2 & \\dots & \\bfv_n\\end{bmatrix} \n",
    "= \\begin{bmatrix}\n",
    "\\bfv_1[1]& \\bfv_2[1] & \\dots & \\bfv_n[1]\\\\\n",
    "\\bfv_1[2]& \\bfv_2[2] & \\dots & \\bfv_n[2]\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "\\bfv_1[m] & \\bfv_2[m] & \\dots & \\bfv_n[m]\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Such a matrix is said to be a $m \\times n$ matrix. It is also written as $\\bfV \\in \\bbR^{m \\times n}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb45f5c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Transpose of a Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f70000e",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Transpose of a matrix $\\bfV$ (denoted as $\\bfV^\\top$) is an operation that swaps rows with columns and columns with rows. For example, the transpose of the above matrix will make it a vertical concatenation of row vectors.\n",
    "\n",
    "$$\\bfV^\\top = \\begin{bmatrix}\\bfv_1^\\top \\\\ \\bfv_2^\\top \\\\ \\vdots \\\\ \\bfv_n^\\top\\end{bmatrix} \n",
    "= \\begin{bmatrix}\n",
    "\\bfv_1[1]& \\bfv_1[2] & \\dots & \\bfv_n[m]\\\\\n",
    "\\bfv_2[1]& \\bfv_2[2] & \\dots & \\bfv_n[m]\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "\\bfv_n[1] & \\bfv_2[2] & \\dots & \\bfv_n[m]\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "If $\\bfV \\in \\bbR^{m \\times n}$, then $\\bfV^\\top \\in \\bbR^{n \\times m}$. The two dimensions get swapped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c37ec4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tranpose of a column vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855cfbb2",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "All vectors are also matrices. By convention, all vectors are considered column matrices and hence called column vectors. A n-D vector $\\bfv = [v_1; \\dots; v_n] \\in \\bbR^n$ is by convention considered a $n \\times 1$ column matrix i.e. $\\bfv \\in \\bbR^{n \\times 1}$.\n",
    "\n",
    "$$ \\bfv = \\begin{bmatrix} v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n  \\end{bmatrix} \\in \\bbR^{n\\times 1}$$\n",
    "\n",
    "The transpose of a column vector is a row vector\n",
    "\n",
    "$$\\bfv^\\top = \\begin{bmatrix} v_1 & v_2 & \\dots & v_n  \\end{bmatrix} \\in \\bbR^{1\\times n}$$\n",
    "\n",
    "Row vectors are always denoted with a tranpose of their corresponding column vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1131bd2a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Matrix-vector product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd4baca",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "For those who know dot product, matrix-vector product is best defined as a collection of dot products. Define a matrix $\\bfV \\in \\bbR^{m \\times n}$ as a vertical concatenation of $m$ n-dimensional row-vectors $\\bfv_1^\\top, \\dots \\bfv_m$\n",
    "\n",
    "$$\\bfV = \\begin{bmatrix}\\bfv_1^\\top \\\\ \\bfv_2^\\top \\\\ \\vdots \\\\ \\bfv_m^\\top\\end{bmatrix} $$\n",
    "\n",
    "The matrix $\\bfV \\in \\bbR^{m \\times n}$ can be multiplied by a n-dimensional column vector $\\bfu \\in  \\bbR^{n}$ with the product defined as the vector-wise dot product vertically concatenated to result in another column vector:\n",
    "\n",
    "$$ \\bfV \\bfu = \\begin{bmatrix}\\bfv_1 \\cdot \\bfu \\\\ \\bfv_2 \\cdot \\bfu \\\\ \\vdots \\\\ \\bfv_m \\cdot \\bfu\\end{bmatrix} \\in \\bbR^{m}$$\n",
    "\n",
    "When $m = 1$, then $\\bfV = \\bfv_1^\\top$ and the matrix product is $\\bfv_1^\\top \\bfu = \\bfv_1 \\cdot \\bfu$. Dot product between two vectors $\\bfv$ and $\\bfu$ is also written as $\\bfv^\\top \\bfu$. Going forward we will prefer $\\bfv^\\top \\bfu$ notation for dot product instead of $\\bfv \\cdot \\bfu$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dfa0de",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Matrix-matrix product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6600e16",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Matrix-matrix product between two matrices $\\bfV \\in \\bbR^{m \\times n}$ and $\\bfU \\in \\bbR^{n \\times p}$ can be defined in terms of matrix-vector product by writing $\\bfU$ as a horizontal concatenation of $p$ $n$-dimensional column vectors $\\bfu_1, \\bfu_2, \\dots, \\bfu_p$.\n",
    "\n",
    "$$ \\bfV \\bfU = \\begin{bmatrix} \\bfV\\bfu_1 & \\bfV\\bfu_2 & \\dots & \\bfV\\bfu_p \\end{bmatrix} \\in \\bbR^{m \\times p}\\\\\n",
    "= \\begin{bmatrix}\n",
    "\\bfv_1^\\top \\bfu_1& \\bfv_1^\\top \\bfu_2 & \\dots & \\bfv_1^\\top \\bfu_p\\\\\n",
    "\\bfv_2^\\top \\bfu_1& \\bfv_2^\\top \\bfu_2 & \\dots & \\bfv_2^\\top \\bfu_p\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "\\bfv_m^\\top \\bfu_1 & \\bfv_m^\\top \\bfu_2 & \\dots & \\bfv_m^\\top \\bfu_p\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The result is a horizontal concatenation of matrix-vector products, where the left matrix $\\bfV$ gets multiplied with each column vector of right matrix $\\bfU$.\n",
    "\n",
    "Another interpretation is that the matrix-matrix product are all possible  dot products between left matrices' row vectors with right matrices' column vectors.\n",
    "\n",
    "Matrix-matrix product or short matrix products do not commute i.e $\\bfV \\bfU \\ne \\bfU \\bfV$ in general."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2dae50-c0a9-4217-b606-e592456fc826",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Identity matrix\n",
    "\n",
    "$$ \\newcommand{\\bfI}{\\mathbf{I}}\\bfI_n = \\begin{bmatrix} \n",
    "    1 & 0 & \\dots & 0 \\\\\n",
    "    0 & 1 & \\dots & 0 \\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    0 & 0 & \\dots & 1 \\\\\n",
    " \\end{bmatrix}$$\n",
    " \n",
    " ### Square matrix\n",
    " \n",
    " A square matrix is a matrix with number of rows equal to the number of columns.\n",
    " \n",
    " ### Inverse of a square matrix\n",
    " \n",
    " A matrix $\\bfV^{-1}$ is called the inverse of a square matrix $\\bfV$ if $\\bfV^{-1} \\bfV = \\bfV^{-1} = \\bfI_n$. The inverse of a square matrix exists only when it is singular i.e the determinant of the matrix is non-zero $\\det(\\bfV) \\ne 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d5ebcd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using vectors for 2D line notation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef40787-74c4-438b-9f87-ecfab586d7fa",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We started from 2D linear models, but we want to work with N-D models where N can be even in thousands or millions. It makes sense to simplify the notation by using vector notation. \n",
    "\n",
    "Recall that the implicit equation for a line is\n",
    "\n",
    "$$\\calL(a, b, c) = \\{(x, y): ax + by + c = 0, x \\in \\bbR, y \\in \\bbR \\}$$\n",
    "\n",
    "We will represent a 2D point (x, y) by a 2D vector $\\bfx = [x; y]$ and the parameters $(a, b)$ with weight vector $\\bfw = [a; b]$.\n",
    "Let's compute the dot product between the two newly defined vectors :\n",
    "\n",
    "$$\\bfw \\cdot \\bfx = ax + by$$\n",
    "\n",
    "The equation of the line under new notation in full its full glory is \n",
    "\n",
    "$$\\calL(\\bfw, c) = \\{\\bfx: \\bfw \\cdot \\bfx + c = 0, \\bfx \\in \\bbR^2 \\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685879cc-26ad-4a9b-822a-f11037a7bf07",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Unique line notation\n",
    "\n",
    "Same line $ax + by + c = 0$ can be represented by multiple equations for the same form. This representation of line is not unique. For example, equations $5x + 2y + 10 = 0$ and $10x + 4y + 20 =0$ represent the same line. In general, for any real number $\\alpha \\ne 0$ all equations $\\alpha a x + \\alpha b y + \\alpha c = 0$ represent the same line. Once can choose an arbitrary non-zero \n",
    "$\\alpha $ for making the equation unique. \n",
    "\n",
    "In vector notation, all non-zero $\\alpha \\bfw \\cdot \\bfx + \\alpha c = 0$ represent the same line. One good candidate for $\\alpha$ is  $\\alpha = \\frac{1}{\\|\\bfw\\|}$, because this changes $\\alpha \\bfw$ to $\\hat{\\bfw}$ a unit vector.\n",
    "\n",
    "$$\\calL(\\hat{\\bfw}, w_0) = \\{\\bfx: \\hat{\\bfw} \\cdot \\bfx + w_0 = 0, \\bfx \\in \\bbR^2 \\}$$\n",
    "\n",
    "where $w_0 = \\frac{c}{\\|\\bfw\\|}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2257c17",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Geometric interpretaion\n",
    "\n",
    "<img src=\"imgs/line-eq-geometric-interpretations.svg\" width=\"400px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a788750c-1f56-4175-a997-bb896da5abbb",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "The new equation of the line has a convinient geometric interpretation. Recall that $\\hat{\\bfw} \\cdot \\bfx$ is the projection of $\\bfx$ on $\\hat{\\bfw}$. In other words, the equation $\\text{proj}_{\\hat{\\bfw}}\\bfx + w_0 = 0$ constrains all vectors on the line to have a constant projection $\\text{proj}_{\\hat{\\bfw}}\\bfx = -w_0$.\n",
    "\n",
    "This means that vector $\\hat{\\bfw}$ is perpendicular to the line and cuts the line a distance $|w_0|$ from the origin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686cb638",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # a vector algebra library\n",
    "\n",
    "a = np.array([0, 1, 2, 3]) # a vector\n",
    "print(\"a=\", a)\n",
    "b = np.array([4, 5, 6, 7]) # another vector\n",
    "print(\"b=\", b)\n",
    "C = np.array([[0, 1, 2, 3],\n",
    "              [4, 5, 6, 7]]) # A matrix\n",
    "print(\"C=\", C)\n",
    "D = np.zeros((2, 4)) # a 2x4 matrix of zeros\n",
    "print(\"D=\", D)\n",
    "E = np.random.rand(2,5) # Random 2x5 matrix of numbers between 0 and 1\n",
    "print(\"E=\", E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cf4507",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"a*0.1 = \", a * 0.1) # element-wise multiplication\n",
    "print(\"C*0.2 = \", C * 0.2) # element-wise multiplication\n",
    "print(\"a*b = \", a * b)   # element-wise multiplication (Note: different from Matlab)\n",
    "print(\"a*b*0.2 = \", a * b * 0.2)   # element-wise multiplication\n",
    "print(\"C @ a = \", C @ a)   # matrix-vector product\n",
    "print(\"C.T = \", C.T)     # matrix transpose\n",
    "print(\"C.T @ D = \", C.T @ D) # matrix-matrix product\n",
    "print(\"a * C = \", a * C)   # so called broadcasting; numpy specific"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8880d09b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Numpy: General Broadcasting Rules\n",
    "\n",
    "When operating on two arrays, NumPy compares their shapes element-wise. It starts with the trailing (i.e. rightmost) dimension and works its way left. Two dimensions are compatible when\n",
    "\n",
    "   1. they are equal, or\n",
    "\n",
    "   2. one of them is 1.\n",
    "  \n",
    "Otherwise a ValueError is raised\n",
    "\n",
    "Ref: https://numpy.org/doc/stable/user/basics.broadcasting.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e50d67",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the following example, both the A and B arrays have axes with length one that are expanded to a larger size during the broadcast operation:\n",
    "\n",
    "    A      (4d array):  8 x 1 x 6 x 1\n",
    "    B      (3d array):      7 x 1 x 5\n",
    "    Result (4d array):  8 x 7 x 6 x 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b2565c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "A = np.random.rand(8, 1, 6, 1)\n",
    "B = np.random.rand(7, 1, 5)\n",
    "(A * B).shape # Returns the shape of the multi dimensional array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790a378e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here are some more examples:\n",
    "\n",
    "    A      (2d array):  5 x 4\n",
    "    B      (1d array):      1\n",
    "    Result (2d array):  ?\n",
    "\n",
    "    A      (2d array):  5 x 4\n",
    "    B      (1d array):      4\n",
    "    Result (2d array):  ?\n",
    "\n",
    "    A      (3d array):  15 x 3 x 5\n",
    "    B      (3d array):  15 x 1 x 5\n",
    "    Result (3d array):  \n",
    "\n",
    "    A      (3d array):  15 x 3 x 5\n",
    "    B      (2d array):       3 x 5\n",
    "    Result (3d array):  ?\n",
    "\n",
    "    A      (3d array):  15 x 3 x 5\n",
    "    B      (2d array):       3 x 1\n",
    "    Result (3d array):  ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00746db",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def points_on_line(hatw, w0, Npts=6, scale=10):\n",
    "    \"\"\" Generate some sample points on a line \"\"\"\n",
    "    assert hatw.shape == (2,) # only works for 2D\n",
    "    perp_hatw = np.array([-hatw[1], hatw[0]])# vector perpendicular to hatw\n",
    "    uniformgrid = np.linspace(-scale//2, scale//2, Npts)\n",
    "    return perp_hatw * uniformgrid[:, None] - w0*hatw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0637614d-ec65-44d8-930c-749b550d4a8b",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Plot a line ax + by + c = 0\n",
    "scale = 10\n",
    "# a, b, c = [scale*(random.random()-0.5) for _ in range(3)] # random number from -10 to 10\n",
    "# abc = scale*(np.random.rand(3)-0.5)  # random number from -10 to 10\n",
    "abc = [3, 2, -6] # pick your favorite line\n",
    "w = abc[:2]\n",
    "hatw = w / np.linalg.norm(w) # What does np.linalg.norm do?\n",
    "w0 = abc[2] / np.linalg.norm(w)\n",
    "\n",
    "# Generate some sample points on a line\n",
    "x = points_on_line(hatw, w0, Npts=6, scale=scale) # Npts x 2 array\n",
    "\n",
    "# Plot the points\n",
    "fig, ax = plt.subplots()\n",
    "stylizeax(ax, (x[:, 0].min(), x[:, 0].max(), x[:, 1].min(), x[:, 1].max())) # numpy allows for multi-dimensional slicing\n",
    "ax.plot(x[:, 0], x[:, 1], '*-') # the line\n",
    "pt0 = -w0*hatw\n",
    "ax.annotate(\"\", xytext=(0, 0), xy=(pt0[0], pt0[1]),\n",
    "            arrowprops=dict(arrowstyle=\"->\", color='r'))\n",
    "ax.text(pt0[0], pt0[1], r\"$-w_0\\hat{\\mathbf{w}}$\", color='r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db131636-ca0f-42a9-b1ea-90ad09cf35f3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear regression: review\n",
    "\n",
    "Let's take the simple linear regression example from STS332 textbook (uploaded on brightspace;page 300; Table 6-1). \n",
    "\n",
    "\"As an illustration, consider the data in Table 6-1. In this table, y is the salt concentration\n",
    "(milligrams/liter) found in surface streams in a particular watershed and x is the percentage of\n",
    "the watershed area consisting of paved roads.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49806742-d179-421d-9cb9-ed9c0721883d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile saltconcentration.tsv\n",
    "#Observation\tSaltConcentration\tRoadwayArea\n",
    "1\t3.8\t0.19\n",
    "2\t5.9\t0.15\n",
    "3\t14.1\t0.57\n",
    "4\t10.4\t0.4\n",
    "5\t14.6\t0.7\n",
    "6\t14.5\t0.67\n",
    "7\t15.1\t0.63\n",
    "8\t11.9\t0.47\n",
    "9\t15.5\t0.75\n",
    "10\t9.3\t0.6\n",
    "11\t15.6\t0.78\n",
    "12\t20.8\t0.81\n",
    "13\t14.6\t0.78\n",
    "14\t16.6\t0.69\n",
    "15\t25.6\t1.3\n",
    "16\t20.9\t1.05\n",
    "17\t29.9\t1.52\n",
    "18\t19.6\t1.06\n",
    "19\t31.3\t1.74\n",
    "20\t32.7\t1.62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0951c0-91fd-48b3-b399-9216a78302ea",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# numpy can import text files separated by seprator like tab or comma\n",
    "salt_concentration_data = np.loadtxt(\"saltconcentration.tsv\")\n",
    "salt_concentration_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d06dda-e251-4260-a440-5b33f4905fea",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the points\n",
    "fig, ax = plt.subplots()\n",
    "# Scatter plot using matplotlib\n",
    "ax.scatter(salt_concentration_data[:, 2], salt_concentration_data[:, 1])\n",
    "ax.set_xlabel(r\"Roadway area %\")\n",
    "ax.set_ylabel(r\"Salt concentration (mg/L)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d65d58",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Least squares regression\n",
    "\n",
    "\n",
    "![](imgs/least-sq-stubs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9d237e-b0da-4538-8aa9-49eee15c0a8b",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The problem of linear regression is to find a line that \"best fits\" the given data. That is we want all the points $\\{(x_1, y_1), \\dots, (x_n, y_n)\\}$ to satisfy the equation of the line $y = mx + c$.  Since we know that there exists no such line, so we will try to make $y \\approxeq mx + c$, by minimizing some error/distance/cost/loss function between $y$ and $mx + c$ for every point $(x_i, y_i)$ in the dataset. The simplest error function that results in nice answers is squared distance:\n",
    "\n",
    "$$e(x_i,y_i) = (y_i - (mx_i + c))^2$$\n",
    "\n",
    "Then we can minimize the total error to find the line:\n",
    "\n",
    "$$m^*, c^* = \\arg~\\min_{m, c} \\sum_{i=1}^n e(x_i,y_i)$$\n",
    "\n",
    "\n",
    "Geometrically, this error minimization corresponds to minimizing the stubs in the following figure:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bb5b44",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Vectorization of Least square regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9acc3a-5fb5-4288-b11b-4ed447d7a151",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "$\\newcommand{\\bfe}{\\mathbf{e}}$\n",
    "$\\newcommand{\\bfm}{\\mathbf{m}}$\n",
    "Recall that the magnitude of a vector $ \\|\\bfv\\| = \\sqrt{v_1^2 + v_2^2 + \\dots + v_n^n}$ has a similar form to the error function. This suggests that we can define an error vector with the signed error for each data point as it's elements\n",
    "\n",
    "$$ \\bfe = \\begin{bmatrix}y_1 - (mx_1 + c)\\\\ y_2 - (mx_2 + c)\\\\ \\vdots \\\\ y_n - (mx_n + c)\\end{bmatrix}$$\n",
    "\n",
    "Minimizing the total error is same as minimizing the square of error vector magnitude \n",
    "\n",
    "$$m^*, c^* = \\arg~\\min_{m, c} \\|\\bfe\\|^2$$\n",
    "\n",
    "While we are at at it let us define $\\bfx = [x_1; \\dots; x_n]$ to denote the vector of all x coordinates of the dataset and $\\bfy = [y_1; \\dots; y_n]$ to denote y coordinates. Then the error vector is:\n",
    "$$ \\bfe = \\bfy - (\\bfx m +  \\mathbf{1}_n c)$$ \n",
    "\n",
    "where $\\mathbf{1}_n$ is a n-D vector of all ones. Finally, we vectorize parameters of the line $\\bfm = [m; c]$. We will also need to horizontally concatenate $\\bfx$ and $\\mathbf{1}_n$. Let's call the result $\\bfX = [\\bfx, \\mathbf{1}_n] \\in \\bbR^{n \\times 2}$. Now, the error vector looks like this:\n",
    "\n",
    "$$ \\bfe = \\bfy - \\bfX \\bfm$$ \n",
    "\n",
    "Expanding the error magnitude:\n",
    "\n",
    "$$ \\|\\bfe\\|^2 = (\\bfy - \\bfX \\bfm)^\\top (\\bfy - \\bfX \\bfm)\n",
    "\\\\\n",
    "= \\bfy^\\top\\bfy + \\bfm^\\top \\bfX^\\top \\bfX \\bfm - 2\\bfy^\\top \\bfX \\bfm \n",
    "$$\n",
    "\n",
    "Our minimization problem in vectorized form is:\n",
    "\n",
    "$$\\bfm^* = \\arg~\\min_{\\bfm} \\bfy^\\top\\bfy + \\bfm^\\top \\bfX^\\top \\bfX \\bfm - 2\\bfy^\\top \\bfX \\bfm $$\n",
    "\n",
    "This is a quadratic equation in $\\bfm$ that can be minimized by equating the derivate to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e180abd0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Two rules of vector derivatives\n",
    "\n",
    "There are two conventions in vector derivatives:\n",
    "1. Gradient convention\n",
    "2. Jacobian convention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66158d29",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Gradient convention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def8784e",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Under gradient convention the derivative of scalar-valued vector function function $f(\\bfx): \\bbR^n \\to \\bbR$ is\n",
    "defined as vertical stacking of element-wise derivatives\n",
    "\n",
    "$$\n",
    "\\newcommand{\\p}{\\partial}\n",
    "\\frac{\\p }{ \\p \\bfx} f(\\bfx) = \n",
    "\\begin{bmatrix}\\frac{\\p f(\\bfx)}{\\p x_1} \\\\ \\vdots \\\\ \\frac{\\p f(\\bfx)}{\\p x_n}\\end{bmatrix} \\in \\bbR^n\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaceefb8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Jacobian convention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d75410",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Under gradient convention the derivative of scalar-valued vector function function $f(\\bfx):  \\bbR^n \\to \\bbR$ is\n",
    "defined as horizontal stacking of element-wise derivatives\n",
    "\n",
    "$$\n",
    "\\newcommand{\\bff}{\\mathbf{f}}\n",
    "\\frac{\\p }{ \\p \\bfx} f(\\bfx) = \n",
    "\\begin{bmatrix}\\frac{\\p f(\\bfx)}{\\p x_1} & \\dots & \\frac{\\p f(\\bfx)}{\\p x_n}\\end{bmatrix} \\in \\bbR^{1 \\times n}$$\n",
    "\n",
    "For a vector-value vector function $\\bff(\\bfx): \\bbR^n \\to \\bbR^m$, Jacobian of $\\bff(\\bfx)$ is the vertical concatentation of gradients transposed, resulting in $m \\times n$ matrix\n",
    "$$\\newcommand{\\bfJ}{\\mathbf{J}}\n",
    "\\bfJ_\\bfx (\\bff(\\bfx)) = \\frac{\\p }{ \\p \\bfx} \\bff(\\bfx) = \n",
    "\\begin{bmatrix}\\frac{\\p f_1(\\bfx)}{\\p \\bfx} \\\\ \\dots \\\\ \\frac{\\p f_m(\\bfx)}{\\p \\bfx}\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "We will use Jacobian convention in this course, because it works nicely with chain rule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99911060",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Derivative of a linear function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f62bfb",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "All scalar-valued linear functions of $\\bfx$ can be written in the form $f(\\bfx) = \\bfc^\\top \\bfx$.\n",
    "\n",
    "\\begin{align}\n",
    "\\newcommand{\\bfc}{\\mathbf{c}}\n",
    "\\newcommand{\\bfA}{\\mathbf{A}}\n",
    "\\frac{\\p }{ \\p \\bfx} \\bfc^\\top \\bfx = \\bfc^\\top\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f34c61",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Derivative of a quadratic function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577db0ce-de88-45f1-8b3d-fd6aded1231d",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "All scalar-valued homogeneous quadratic functions of $\\bfx$ can be written in the form $f(\\bfx) = \\bfx^\\top \\bfA \\bfx$.\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\p }{ \\p \\bfx} \\bfx^\\top \\bfA \\bfx = \\bfx^\\top (\\bfA + \\bfA^\\top)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d3f02d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Back to Least square regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7635fe62-e801-43e3-9e87-13ddf67fb586",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "\\begin{align}\n",
    "\\mathbf{0}^\\top &= \\frac{\\p }{\\p \\bfm} ( \\bfy^\\top\\bfy + \\bfm^\\top \\bfX^\\top \\bfX \\bfm - 2\\bfy^\\top \\bfX \\bfm)\\\\\n",
    "      &= 2 {\\bfm^*}^\\top \\bfX^\\top \\bfX  - 2\\bfy^\\top \\bfX\n",
    "\\end{align}\n",
    "\n",
    "This gives us the solution\n",
    "$$ \\bfm^* = (\\bfX^\\top \\bfX)^{-1} \\bfX^\\top \\bfy $$\n",
    "\n",
    "The symbol $\\bfV^{-1}$ is called inverse of matrix $\\bfV$.\n",
    "\n",
    "The term $(\\bfX^\\top \\bfX)^{-1} \\bfX^\\top$ is also called the pseudo-inverse of a matrix $\\bfX$, denoted as $\\bfX^\\dagger$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cd5ac8-3607-4a2a-bb6b-5690a9a73aab",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "n = salt_concentration_data.shape[0]\n",
    "bfx = salt_concentration_data[:, 2:3]\n",
    "bfy = salt_concentration_data[:, 1:2]\n",
    "bfX = np.hstack((bfx, np.ones((bfx.shape[0], 1))))\n",
    "bfX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fb0a68-d642-4461-a025-f2442b89ab3d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "bfm = np.linalg.inv(bfX.T @ bfX) @ bfX.T @ bfy\n",
    "print(bfm)\n",
    "bfm, *_ = np.linalg.lstsq(bfX, bfy, rcond=None)\n",
    "print(bfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a620f13-0f8c-4515-94fc-66b80eca067d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "m = bfm.flatten()[0]\n",
    "c = bfm.flatten()[1]\n",
    "\n",
    "# Plot the points\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(salt_concentration_data[:, 2], salt_concentration_data[:, 1])\n",
    "ax.set_xlabel(r\"Roadway area $\\%$\")\n",
    "ax.set_ylabel(r\"Salt concentration (mg/L)\")\n",
    "x = salt_concentration_data[:, 2]\n",
    "y = m * x + c\n",
    "# Plot the points\n",
    "ax.plot(x, y, 'r-') # the line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce907f0-d683-436c-8e60-b1dbb284225c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise 1\n",
    "\n",
    "Derive the equations for least square linear regression when the equation of line is $\\hat{\\bfw}^\\top \\bfx + w_0 = 0$ instead of $y = mx + c$.\n",
    "\n",
    "Hint: Convert the least square problem into equation of the form $\\bfv^* = \\arg~\\min_{\\bfv}\\|\\mathbf{L}\\bfv\\|^2$ such that $\\bfv^\\top \\bfv = 1$. Solve by finding null space of $\\mathbf{L}$. $\\bfv$ lies in the nullspace of $\\mathbf{L}$. The nullspace of $\\mathbf{L}$ is the last eigenvector (corresponding to the smallest eigenvalue) of $\\mathbf{L}^\\top\\mathbf{L}$.\n",
    "\n",
    "The error $e(x_i, y_i) = (y - (mx + c))^2$ can be visualized as distance of observed point from the fit line parallel to y-axis. Draw the visual for the errors of the form:  $e(\\bfx_i) = (\\hat{\\bfw}^\\top \\bfx_i + w_0 - 0)^2$. You do not need to use matplotlib. You can draw by hand or editing software."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "rise": {
   "center": false,
   "enable_chalkboard": true,
   "showNotes": true
  },
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
